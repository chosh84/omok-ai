{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RgOHyZDpREu",
    "outputId": "e868dba0-d3b6-44f0-e33d-1ea665512484"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mzPKfRrrzJH",
    "outputId": "e956979f-d823-4ccc-ffd4-0e1f272b71be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v12fUF3_o6JR",
    "outputId": "c31839e8-c2ca-4d58-b3b4-585cd2e2d3ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1000/22536 [00:08<03:08, 114.28it/s]\n"
     ]
    }
   ],
   "source": [
    "w, h = 20, 20\n",
    "base_path = os.path.join('./dataset/', '*.npz')\n",
    "\n",
    "file_list = glob(base_path)\n",
    "\n",
    "x_data, y_data = [], []\n",
    "cut = 0\n",
    "for file_path in tqdm(file_list):\n",
    "  data = np.load(file_path)\n",
    "  x_data.extend(data['inputs'])\n",
    "  y_data.extend(data['outputs'])\n",
    "  # too many data for google colab, so I've only use 5000\n",
    "  if cut == 1000:   \n",
    "    break\n",
    "  else:\n",
    "    cut += 1\n",
    "\n",
    "# It's faster to convert np.array to tensor rather than conver np.ndarray to tensor directly\n",
    "x_data = torch.tensor(np.array(x_data, np.float32)).reshape((-1, h, w, 1))\n",
    "y_data = torch.tensor(np.array(y_data, np.float32)).reshape((-1, h * w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LfqTULa5szGF"
   },
   "outputs": [],
   "source": [
    "# Set DataSet\n",
    "full_dataset = TensorDataset(x_data, y_data)\n",
    "\n",
    "del x_data, y_data\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "#split datasets\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Define data loader0\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DTJClDbW8flc"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    # L1 ImgIn shape=(?, 20, 20, 1)\n",
    "    #    Conv     -> (?, 20, 20, 64)\n",
    "    self.layer1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=\"same\"),\n",
    "        torch.nn.ReLU())\n",
    "    \n",
    "    # L2 ImgIn shape=(?, 20, 20, 64)\n",
    "    #    Conv     -> (?, 20, 20, 128)\n",
    "    self.layer2 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=7, stride=1, padding=\"same\"),\n",
    "        torch.nn.ReLU())\n",
    "    \n",
    "    # L3 ImgIn shape=(?, 20, 20, 128)\n",
    "    #    Conv     -> (?, 20, 20, 256)\n",
    "    self.layer3 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(128, 256, kernel_size=7, stride=1, padding=\"same\"),\n",
    "        torch.nn.ReLU())\n",
    "    \n",
    "    # L4 ImgIn shape=(?, 20, 20, 256)\n",
    "    #    Conv     -> (?, 20, 20, 128)\n",
    "    self.layer4 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(256, 128, kernel_size=7, stride=1, padding=\"same\"),\n",
    "        torch.nn.ReLU())\n",
    "    \n",
    "    # L5 ImgIn shape=(?, 20, 20, 128)\n",
    "    #    Conv     -> (?, 20, 20, 64)\n",
    "    self.layer5 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(128, 64, kernel_size=7, stride=1, padding=\"same\"),\n",
    "        torch.nn.ReLU())\n",
    "    \n",
    "    # L6 ImgIn shape=(?, 20, 20, 64)\n",
    "    #    Conv     -> (?, 20, 20, 1)\n",
    "    self.layer6 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(64, 1, kernel_size=1, stride=1, padding=\"same\"))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = torch.nn.Sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 4651\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_dl)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# H(x) 계산\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m hypothesis \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# cost 계산\u001b[39;00m\n\u001b[1;32m     12\u001b[0m cost \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(hypothesis, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs + 1):\n",
    "    \n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, y in train_dl:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # H(x) 계산\n",
    "        hypothesis = model.forward(X)\n",
    "        # cost 계산\n",
    "        cost = F.binary_cross_entropy(hypothesis, y)\n",
    "        \n",
    "        # cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8V12c8zo6JU",
    "outputId": "42b19a34-cc39-48a9-abda-d32e42e7ccf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 64)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 128)       401536    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 256)       1605888   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       1605760   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 64)        401472    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 1)         65        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 400)               0         \n",
      "=================================================================\n",
      "Total params: 4,017,921\n",
      "Trainable params: 4,017,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, 7, activation='relu', padding='same', input_shape=(h, w, 1)),\n",
    "    layers.Conv2D(128, 7, activation='relu', padding='same'),\n",
    "    layers.Conv2D(256, 7, activation='relu', padding='same'),\n",
    "    layers.Conv2D(128, 7, activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, 7, activation='relu', padding='same'),\n",
    "    layers.Conv2D(1, 1, activation=None, padding='same'),\n",
    "    layers.Reshape((h * w,)),\n",
    "    layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqslnH1Ao6JW"
   },
   "source": [
    "- kernel 7,5,3,3,3: 53.3\n",
    "- kernel all 7: 56.12\n",
    "- kernel all 7, double kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jfufhzao6JX",
    "outputId": "6b7ad1b7-b630-4301-bcde-5d5d1c982f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    2/17638 [..............................] - ETA: 9:00 - loss: 0.0050 - acc: 0.6035WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0226s vs `on_train_batch_end` time: 0.0386s). Check your callbacks.\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.6081\n",
      "Epoch 00001: val_acc improved from -inf to 0.58375, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1091s 62ms/step - loss: 0.0049 - acc: 0.6081 - val_loss: 0.0052 - val_acc: 0.5837\n",
      "Epoch 2/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.6206\n",
      "Epoch 00002: val_acc improved from 0.58375 to 0.58817, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1095s 62ms/step - loss: 0.0048 - acc: 0.6206 - val_loss: 0.0052 - val_acc: 0.5882\n",
      "Epoch 3/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.6330\n",
      "Epoch 00003: val_acc improved from 0.58817 to 0.59378, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1096s 62ms/step - loss: 0.0046 - acc: 0.6330 - val_loss: 0.0052 - val_acc: 0.5938\n",
      "Epoch 4/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.6449\n",
      "Epoch 00004: val_acc improved from 0.59378 to 0.59846, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1097s 62ms/step - loss: 0.0045 - acc: 0.6449 - val_loss: 0.0051 - val_acc: 0.5985\n",
      "Epoch 5/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.6565\n",
      "Epoch 00005: val_acc improved from 0.59846 to 0.60367, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1097s 62ms/step - loss: 0.0044 - acc: 0.6565 - val_loss: 0.0051 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.6672\n",
      "Epoch 00006: val_acc improved from 0.60367 to 0.60586, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1096s 62ms/step - loss: 0.0043 - acc: 0.6672 - val_loss: 0.0051 - val_acc: 0.6059\n",
      "Epoch 7/10\n",
      "17637/17638 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.6775\n",
      "Epoch 00007: val_acc improved from 0.60586 to 0.60938, saving model to ./models/20201213_202430.h5\n",
      "17638/17638 [==============================] - 1095s 62ms/step - loss: 0.0042 - acc: 0.6775 - val_loss: 0.0051 - val_acc: 0.6094\n",
      "Epoch 8/10\n",
      " 4983/17638 [=======>......................] - ETA: 12:07 - loss: 0.0040 - acc: 0.6957"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('./models/%s.h5' % (start_time), monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, mode='auto')\n",
    "    ],\n",
    "    validation_data=(x_val, y_val),\n",
    "    use_multiprocessing=True,\n",
    "    workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9pisNbwo6JZ",
    "outputId": "352c8347-b394-4390-b9b3-6c099546a6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0-1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0-1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        print('%2d' % x_val[i][y, x], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zb0XqcSo6Ja",
    "outputId": "54d33d7f-dd9b-4fb5-95e0-9c49fdcb3acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 9 0.99919564\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.expand_dims(x_val[i], axis=0)).squeeze()\n",
    "y_pred = y_pred.reshape((h, w))\n",
    "\n",
    "y, x = np.unravel_index(np.argmax(y_pred), y_pred.shape)\n",
    "\n",
    "print(x, y, y_pred[y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "218d8KoNo6Jb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfY8k3u7o6Jc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxlVfs3To6Jc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOxZrs7to6Jd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
